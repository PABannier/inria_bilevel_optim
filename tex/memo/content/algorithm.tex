%!TEX root = ../article.tex


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithms}
\label{sec:algorithms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Considering the techniques mentioned by \citet{Jaggi13}, you can use a different algorithm a in say \Cref{alg:DC}



% {\fontsize{4}{4}\selectfont
% \begin{algorithm}[h]  % again h stands for here
% \SetKwInOut{Input}{input}
% \SetKwInOut{Init}{init}
% \SetKwInOut{Parameter}{param}
% \caption{\textsc{Implicit differentiation}
% }
% %
% \Input{$
%     X \in \bbR^{n \times p},
%     y \in \bbR^{n},
%     \lambda \in \bbR,
%     n_{\text{iter}} \in \bbN$}
%     \tcp{jointly compute coef. and Jacobian}

%     \If{Lasso}{
%     Get $\beta = Lasso(X, y, \lambda, n_{\text{iter}})
%     $ and its support $\hat S$.

%     $\hat J_{\phantom{\hat S}} = 0_{p}$
%     \tcp{affectation}

%     $\hat J_{\hat S} =
%     - n e^\lambda (X_{\hat S}^\top X_{\hat S})^{-1} \sign \beta_{\hat S} $
%     }
%     \If{wLasso}{
%     Get $\beta = wLasso(X, y, \lambda, n_{\text{iter}})
%     $ and its support $\hat S$.

%     $\hat J = 0_{p \times p}$

%     $\hat J_{\hat S, \hat S} =
%     - (X_{\hat S}^\top X_{\hat S})^{-1}
%     \diag ( n e^{\lambda_{\hat S}}
%     \odot \sign \beta_{\hat S})$
%     }
% \For{$k = 0,\dots, n_{\text{iter\_jac}} - 1$
%     }{a = 1}

% \Return{$\beta, \hat J$}
% \label{alg:compute_jac_implicit_diff}
% \end{algorithm}
% }


% It is also possible to use the standard citation style \cite{Tibshirani96}.
